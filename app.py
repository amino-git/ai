import streamlit as st
import pandas as pd
import joblib
import re
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neural_network import MLPClassifier
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score, recall_score, f1_score
from nltk.corpus import stopwords
from nltk.stem.isri import ISRIStemmer
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# ØªØ­Ù…ÙŠÙ„ stopwords Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
nltk.download('stopwords', quiet=True)

# Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "mlp" not in st.session_state:
    st.session_state.mlp = None
if "vectorizer" not in st.session_state:
    st.session_state.vectorizer = None
if "dark_mode" not in st.session_state:
    st.session_state.dark_mode = False

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§
if st.session_state.mlp is None or st.session_state.vectorizer is None:
    if os.path.exists("mlp_model.pkl") and os.path.exists("tfidf_vectorizer.pkl"):
        st.session_state.mlp = joblib.load("mlp_model.pkl")
        st.session_state.vectorizer = joblib.load("tfidf_vectorizer.pkl")

# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
def clean_text(text, lang="ar"):
    text = str(text).lower()
    text = re.sub(r"http\S+|www.\S+", "", text)
    text = re.sub(r"@\w+", "", text)
    text = re.sub(r"#", "", text)
    text = re.sub(r"\d+", "", text)
    if lang == "ar":
        text = re.sub(r"[^\w\s\u0600-\u06FF]", "", text)
    else:
        text = re.sub(r"[^\w\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="Amily ğŸ“", layout="centered")

# ========= ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ==========
st.title("Amily ğŸ“")
st.subheader("ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")

user_tweet = st.text_input("Ø§Ø¯Ø®Ù„ ØªØºØ±ÙŠØ¯ØªÙƒ Ù‡Ù†Ø§")
lang = st.radio("Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©", ["Arabic", "English"], key="user_lang")

if st.button("ØµÙ†Ù Ø§Ù„ØªØºØ±ÙŠØ¯Ø© (Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)"):
    if st.session_state.mlp and st.session_state.vectorizer:
        tweet_clean = clean_text(user_tweet, lang="ar" if lang=="Arabic" else "en")
        if tweet_clean.strip() == "":
            st.warning("âš ï¸ Ø§Ù„Ù†Øµ ÙØ§Ø±Øº.")
        else:
            tweet_vector = st.session_state.vectorizer.transform([tweet_clean])
            pred = st.session_state.mlp.predict(tweet_vector)[0]
            st.info("â¡ï¸ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©" if pred == 1 else "â¡ï¸ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø³Ù„Ø¨ÙŠØ©")
    else:
        st.warning("âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨ Ø¨Ø¹Ø¯.")

st.markdown("---")

# ========= ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø¯ÙŠØ± ==========
if not st.session_state.logged_in:
    st.subheader("ğŸ”’ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ù…Ø¯ÙŠØ±")
    username = st.text_input("Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    password = st.text_input("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password")
    if st.button("Ø¯Ø®ÙˆÙ„"):
        if username == "admin" and password == "1234":
            st.session_state.logged_in = True
            st.success("ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„!")
        else:
            st.error("Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„")

# ========= ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø¯ÙŠØ± ==========
if st.session_state.logged_in:
    st.title("ğŸ‘¨â€ğŸ’¼ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø¯ÙŠØ±")
    
    # ========== ØªØ¯Ø±ÙŠØ¨ ØªØºØ±ÙŠØ¯Ø© ÙˆØ§Ø­Ø¯Ø© ==========
    st.subheader("âœ¨ ØªØ¯Ø±ÙŠØ¨ ØªØºØ±ÙŠØ¯Ø© ÙˆØ§Ø­Ø¯Ø©")

    single_tweet = st.text_input("Ø§ÙƒØªØ¨ ØªØºØ±ÙŠØ¯Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    single_label = st.radio("Ù†ÙˆØ¹ Ø§Ù„ØªØºØ±ÙŠØ¯Ø©", ["Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©", "Ø³Ù„Ø¨ÙŠØ©"])

    if st.button("ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªØºØ±ÙŠØ¯Ø©"):
        if single_tweet.strip() == "":
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¯Ø±ÙŠØ¨ Ù†Øµ ÙØ§Ø±Øº.")
        else:
            clean = clean_text(single_tweet)

            # Ø¥Ø°Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ â†’ Ø£Ù†Ø´Ø¦ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¬Ø¯ÙŠØ¯Ù‹Ø§
            if st.session_state.vectorizer is None:
                st.session_state.vectorizer = TfidfVectorizer(max_features=25000, ngram_range=(1,2))
                X_init = st.session_state.vectorizer.fit_transform([clean])
            else:
                try:
                    X_init = st.session_state.vectorizer.transform([clean])
                except:
                    st.warning("âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªØ§Ø¬ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ ÙƒØ§Ù…Ù„ Ù„Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª.")
                    X_init = st.session_state.vectorizer.fit_transform([clean])

            y_value = 1 if single_label == "Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©" else 0

            if st.session_state.mlp is None:
                st.session_state.mlp = MLPClassifier(hidden_layer_sizes=(200,100), warm_start=True, max_iter=1)
                st.session_state.mlp.partial_fit(X_init, [y_value], classes=[0,1])
            else:
                st.session_state.mlp.partial_fit(X_init, [y_value])

            joblib.dump(st.session_state.mlp, "mlp_model.pkl")
            joblib.dump(st.session_state.vectorizer, "tfidf_vectorizer.pkl")

            st.success("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬!")

    st.markdown("---")

    # ========== Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ==========
    st.subheader("Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ CSV/TSV")
    file = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù", type=["csv","tsv"])
    file_lang = st.radio("Ù„ØºØ© Ø§Ù„Ù…Ù„Ù", ["Arabic","English"])

    if file:
        sep = "\t" if file.name.endswith(".tsv") else ","
        df = pd.read_csv(file, sep=sep, header=None, names=["label","text"])
        df = df.dropna()

        if file_lang == "Arabic":
            df = df[df["text"].str.contains(r'[\u0600-\u06FF]')]

        df["clean_text"] = df["text"].apply(lambda x: clean_text(x, "ar" if file_lang=="Arabic" else "en"))
        df = df[df["clean_text"].str.strip() != ""]

        df_majority = df[df.label=="neg"]
        df_minority = df[df.label=="pos"]

        if len(df_minority) > 0 and len(df_majority) > 0:
            df_minority_up = resample(df_minority, replace=True, n_samples=len(df_majority))
            df_bal = pd.concat([df_majority, df_minority_up])
        else:
            df_bal = df.copy()

        if st.button("ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù"):
            if df_bal.empty:
                st.error("âš ï¸ Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø©.")
            else:
                with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨..."):
                    vectorizer = TfidfVectorizer(max_features=25000, ngram_range=(1,2))
                    X = vectorizer.fit_transform(df_bal["clean_text"])
                    y = df_bal["label"].map({"neg":0,"pos":1})

                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

                    mlp = MLPClassifier(hidden_layer_sizes=(200,100), warm_start=True, max_iter=1)

                    progress_bar = st.progress(0)
                    for epoch in range(20):
                        mlp.fit(X_train, y_train)
                        progress_bar.progress((epoch+1)/20)

                    st.session_state.mlp = mlp
                    st.session_state.vectorizer = vectorizer

                    joblib.dump(mlp, "mlp_model.pkl")
                    joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

                    st.success("âœ… ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨!")

                y_pred = mlp.predict(X_test)
                acc = accuracy_score(y_test, y_pred)
                st.info(f"Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {acc:.2f}")
